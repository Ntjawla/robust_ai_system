{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f158bf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Explainability for Sentiment and Intent Models\\n\",\n",
    "    \"This notebook demonstrates how to interpret predictions using SHAP and LIME for text classification models.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Imports\\n\",\n",
    "    \"import torch\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"from transformers import AutoTokenizer, BertForSequenceClassification\\n\",\n",
    "    \"import shap\\n\",\n",
    "    \"from lime.lime_text import LimeTextExplainer\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Load sample data\\n\",\n",
    "    \"df = pd.read_csv('../data/IMDB_dataset.csv')\\n\",\n",
    "    \"sample_texts = df['review'].tolist()[:5]  # Take first 5 reviews\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Load sentiment model\\n\",\n",
    "    \"sentiment_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\\n\",\n",
    "    \"sentiment_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\\n\",\n",
    "    \"\\n\",\n",
    "    \"def predict_sentiment(texts):\\n\",\n",
    "    \"    inputs = sentiment_tokenizer(texts, return_tensors='pt', padding=True, truncation=True)\\n\",\n",
    "    \"    outputs = sentiment_model(**inputs)\\n\",\n",
    "    \"    probs = torch.softmax(outputs.logits, dim=1).detach().numpy()\\n\",\n",
    "    \"    return probs\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# SHAP explainability\\n\",\n",
    "    \"explainer = shap.Explainer(predict_sentiment, tokenizer=sentiment_tokenizer)\\n\",\n",
    "    \"shap_values = explainer(sample_texts)\\n\",\n",
    "    \"shap.plots.text(shap_values[0])  # Explain first review\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# LIME explainability\\n\",\n",
    "    \"class_names = ['negative', 'positive']\\n\",\n",
    "    \"explainer_lime = LimeTextExplainer(class_names=class_names)\\n\",\n",
    "    \"\\n\",\n",
    "    \"for text in sample_texts[:2]:  # Explain first 2 reviews\\n\",\n",
    "    \"    exp = explainer_lime.explain_instance(text, predict_sentiment, num_features=10)\\n\",\n",
    "    \"    exp.show_in_notebook(text=True)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Notes:\\n\",\n",
    "    \"- `SHAP` provides global and local interpretability.\\n\",\n",
    "    \"- `LIME` provides local feature importance for individual predictions.\\n\",\n",
    "    \"- You can replicate the same for your **intent model** by loading it similarly and defining a prediction function.\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\",\n",
    "   \"version\": \"3.10\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
